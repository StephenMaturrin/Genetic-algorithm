import random as rand
import numpy as np
from collections import OrderedDict
import pandas as pd
import os
from datetime import datetime
from project.generic_functions import  get_logdir
class induvidual():


#TODO differentiation between equals model
#TODO may I use objects or dictionaries ?
#TODO the layers are also features

    def __init__(self,input_layer=12,output_layer=1):
        self.input_layer = input_layer
        self.output_layer = output_layer
        self.learning_rate= 0
        self.n_layers = []
        self.NN_ID=[]
        self.log_individual = {"Fitness": 0, "ID_father": None, "ID_mother": None, "ID_population": None, "NN_ID": None, "layout": None,
                          "Learning_rate": None}

    def create_individial(self):

        self.learning_rate = np.random.randint(1,10)**-np.random.randint(1,4)
        self.NN_ID.append(self.learning_rate)

        self.log_individual.update({"Learning_rate":self.learning_rate})
        layers = np.random.randint(1,4)
        self.n_layers.append(self.input_layer)
        self.NN_ID.append(self.n_layers[-1])

        for i in range(layers):
            self.n_layers.append(np.random.randint(1,64))
            self.NN_ID.append(self.n_layers[-1])
        self.n_layers.append(self.output_layer)
        self.NN_ID.append(self.n_layers[-1])

        self.log_individual.update({"NN_ID":self.NN_ID})
        self.log_individual.update({"layout": self.n_layers})


        return self.log_individual



    def get_gen(self):
        return self.log_individual

    def update_gen(self,parameter, value):
        self.log_individual.update({parameter:value})

    def get_gen(self,parameter):
        return self.log_individual[parameter]

population = []
aux_population= {}
#


def create_individual(first, n_layers=5,n_neurons=64 ,input_layer=None,output_layer=None,NN_ID=None,learning_rate=None):
    NN_ID = []
    if (first ):
        learning_rate = np.random.randint(1, 10) ** -np.random.randint(1,5)
        layers = np.random.randint(1,n_layers)
        n_layers=[]
        n_layers.append(input_layer)

        # NN_ID.append(learning_rate)
        NN_ID.append(n_layers[-1])

        for i in range(layers):
            n_layers.append(np.random.randint(2, n_neurons ))
            NN_ID.append(n_layers[-1])
        n_layers.append(output_layer)
        NN_ID.append(n_layers[-1])
    else:


        NN_ID.append(learning_rate)
        for i in n_layers:
            NN_ID.append(i)

    # n_layers = np.array(n)
    individual = {"Fitness": 0,
            "NN_ID": [[str(i) for i in  NN_ID]],
            "layout": [[str(i) for i in n_layers]],
            "Learning_rate": 0.01}

    return individual








def create_population_simple(n_population, n_layers=5,n_neurons=64,input_layer=12, output_layer=1):
    population =[]
    for i in range(n_population):
        population.append(pd.DataFrame(create_individual(first=True,n_layers=n_layers, n_neurons=n_neurons,input_layer=input_layer,output_layer=output_layer),index=[i]))

    return  pd.concat(population)












def selection (population, n_best,n_worst):
    return population.head(n_best), population.tail(n_worst)
    # return population.iloc[:n_best],population.iloc[n_best:n_best+n_worst]


def ranking (population):
    df = population.sort_values(by='Fitness',ascending=False)


    return df

# https://www.quora.com/What-is-your-thought-process-when-choosing-a-neural-network-architecture
def overcrossing (group1,group2,crossover_likelihood):

    # print("group2",group2)
    # print("group1",group1)

    # print(group1)
    selected = group1.append(group2)
    # print("selected",selected)

    population = []
    bag = []
    index = 0
    for index1 in range(len(selected)):

        induvidual_id_g1 = selected.layout
        induvidual_id_g1 = induvidual_id_g1.iloc[index1]
        induvidual_id_g1 = np.array([float(i) for i in induvidual_id_g1])
        A1 = np.array([i for i in induvidual_id_g1[0:int(len(induvidual_id_g1) / 2)]])
        B1 = np.array([i for i in induvidual_id_g1[int(len(induvidual_id_g1) / 2):len(induvidual_id_g1)]])

        # print("A1",A1)
        # print("B1", B1)
        for index2 in range(index1+1,len(selected)):
            induvidual_id_g2 = selected.layout
            induvidual_id_g2 = induvidual_id_g2.iloc[index2]
            induvidual_id_g2 = np.array([float(i) for i in induvidual_id_g2])
            A2 = np.array([i for i in induvidual_id_g2[0:int(len(induvidual_id_g2) / 2)]])
            B2 = np.array([i for i in induvidual_id_g2[int(len(induvidual_id_g2) / 2):len(induvidual_id_g2)]])
            # print("A2", A2)
            # print("B2", B2)

            #  crossover likelihood(80 % -95 %)
            # We may want that parents survive in the next generation
            # In order to do that, we need to give them a likelihood  (a little chance)
            p=np.random.rand()
            if ( p< crossover_likelihood):
                # print ("ENTRE")
                new_indiv_1 = np.concatenate([A2, B1])
                new_indiv_2 = np.concatenate([A1, B2])
            else:
                new_indiv_1 = induvidual_id_g1
                new_indiv_2 = induvidual_id_g2

            if new_indiv_1.tolist() not in bag:
                population.append(
                    pd.DataFrame(create_individual(
                        first=False,
                        learning_rate=0.01,
                        n_layers=new_indiv_1)))

                bag.append(new_indiv_2.tolist())
                # print(len(population))


            if new_indiv_2.tolist() not in bag:
                population.append(
                    pd.DataFrame(create_individual(
                        first=False,
                        n_neurons=64,
                        learning_rate=0.01,
                        n_layers=new_indiv_2)))
                bag.append(new_indiv_2.tolist())


                # print(len(population))
                # print(len(bag))



            #
            # print("P --- > ",p)
            #
            # print("new_indiv_2", new_indiv_2)
            # print("new_indiv_1", new_indiv_1)



    print("Bag_list", bag )
    population = pd.concat(population)
    population = population.reset_index()
    # print(len(population))
    # population = population.drop_duplicates(population)
    # print(len(population))
    # print("REINDEX3333333333333333333333333333")
    # print(population)
    now = datetime.utcnow().strftime('%B-%d-%Y-%H:%M:%S')
    population.to_csv(os.getcwd() + "/test/{}{}".format(now, ".csv"), sep=';', header=True, float_format='%.8f',
                      index=False)
    population.to_csv("original.csv", sep=';', header=True, float_format='%.8f', index=False)
    # print(population)
    return population





    # population=[]
    # for index_g1 in range(len(group1)):
    #
    #     induvidual_id_g1 = group1.layout
    #     induvidual_id_g1 = induvidual_id_g1.iloc[index_g1]
    #     induvidual_id_g1 = np.array([float(i) for i in induvidual_id_g1])
    #     A1 = np.array([i for i in induvidual_id_g1[0:int(len(induvidual_id_g1) / 2)]])
    #     B1 = np.array([i for i in induvidual_id_g1[int(len(induvidual_id_g1) / 2):len(induvidual_id_g1)]])
    #
    #     for index_g2 in range(len(group2)):
    #         induvidual_id_g2 = group2.layout
    #         induvidual_id_g2 = induvidual_id_g2.iloc[index_g2]
    #         induvidual_id_g2 = np.array([float(i) for i in induvidual_id_g2])
    #         A2 = np.array([i for i in induvidual_id_g2[0:int(len(induvidual_id_g2) / 2)]])
    #         B2 = np.array([i for i in induvidual_id_g2[int(len(induvidual_id_g2) / 2):len(induvidual_id_g2)]])
    #
    #         #  crossover likelihood(80 % -95 %)
    #         # We may want that parents survive in the next generation
    #         # In order to do that, we need to give them a likelihood  (a little chance)
    #         if(np.random.rand()<crossover_likelihood):
    #             new_indiv_1 = np.concatenate([A2, B1])
    #             new_indiv_2 = np.concatenate([A1, B2])
    #         else:
    #             new_indiv_1 = induvidual_id_g1
    #             new_indiv_2 = induvidual_id_g2
    #
    #
    #
    #         population.append(
    #             pd.DataFrame(create_individual(
    #                 first=False,
    #                 n_neurons= 64,
    #                 learning_rate=0.01,
    #                 n_layers=new_indiv_2)))
    #         population.append(
    #             pd.DataFrame(create_individual(
    #                 first=False,
    #                 learning_rate=0.01,
    #                 n_layers=new_indiv_1)))
    #
    # population = pd.concat(population)
    # now = datetime.utcnow().strftime('%B-%d-%Y-%H:%M:%S')
    # population.to_csv(os.getcwd() + "/test/{}{}".format(now, ".csv"), sep=';', header=True, float_format='%.8f',
    #                       index=False)
    # population.to_csv("original.csv", sep=';', header=True, float_format='%.8f', index=False)
    #
    # return population


def mutation (population,n_population,mutation_likelihood):
    population_mut =[]
    for index in range(len(population)):

        # print("IN\n", population.iloc[index])
        if (np.random.rand() <= mutation_likelihood):
            # print("MUTADO ")

            ly = np.array([float(i) for i in population.iloc[index].layout])
            population.iloc[index].Learning_rate = population.iloc[index].Learning_rate* np.random.rand()
            lr = population.iloc[index].Learning_rate
            layer_selected = np.random.randint(1,len(ly)-1)
            ly[layer_selected]= ly[layer_selected]+ np.random.randint(-ly[layer_selected]+1,ly[layer_selected])




        else:
            ly =population.iloc[index].layout
            lr = population.iloc[index].Learning_rate
        # print("OUT\n", lr, ly)
        population_mut.append(
                pd.DataFrame(create_individual(
                    first=False,
                    learning_rate=lr,
                    n_layers=ly), index=[index]))


    population_mut= pd.concat(population_mut)

    now = datetime.utcnow().strftime('%B-%d-%Y-%H:%M:%S')
    population_mut.to_csv("/home/tmpext4/ms255613/ANN/AG_log/L2/{}{}".format(now, ".csv"), sep=';', header=True, float_format='%.8f', index=False)
    print("/home/tmpext4/ms255613/ANN/AG_log/L2/")
    return population_mut



#
#
#
# pop = create_population_simple(100)
# pop = pd.concat(pop)
#
#
# population_ranked = ranking(pop)
# group1, group2 = selection(population_ranked,n_best=5,n_worst=5)
# pop = overcrossing(group1,group2,0.9)
# pop = mutation(pop,50,mutation_likelihood=0.05)
#
# print(pop)
#

